{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "This Python notebook ilustrates some concepts related of precision and recall in classification using MNIST dataset from Scikit-Learn.\n",
    "\n",
    "First, we need to import MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check for X and y shape of the MNIST data. There are 70,000 images and each image has 784 features (28x28 pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's peek at one digit from the dataset and display it using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[27000]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap=matplotlib.cm.binary, interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for the label of this random digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[27000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a classification system using MNIST. Let's create the train set and the test set. The MNIST dataset is already split into a training set (the first 60,000 images) and a test set (the last 10,000 images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now shuffle the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Binary Classifier\n",
    "\n",
    "Let's try to identify one digit. Let's create a \"5-detector\" capable of distinguishing between just two classes, 5 and not-5. Let's create the target vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == '5')\n",
    "y_test_5 = (y_test == '5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now pick a classifier and train it. Let's pick a Stochastic Gradient Descent (SGD) classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the classifier to detect images of the number 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model's Performance\n",
    "\n",
    "There are many performance measures available. Let's first measure the accuracy of the model using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95885, 0.9673 , 0.9156 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cv=3 means we wanto to use K-fold cross-validation with three folds. Each fold contain a representative ratio of each class. K-fold means splitting the training set into K-folds (three in this case), then make predictions and evaluating them on each fold using a model trained on the remaining folds.\n",
    "\n",
    "We saw that even with a basic classifier we got above 90% accuracy.\n",
    "\n",
    "If we create a dumb classifier that just classifies every image in the \"non-5\" class we will have over 90% accuracy too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9082 , 0.9099 , 0.91085])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only about 10% of the images are 5s, so if we always guess that an image is not a 5, we will be right about 90% of the time !\n",
    "\n",
    "This demonstrates why accuracy is generally not the preferred performance measure for classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "A better way to evaluate the performance of a classifier is to look at the confusion matrix. The general idea is to count the number of times instances of class A are classified as B. For example, to know the number of times the classifier confused images of 5s with 3s, we will look in the 5th row and 3rd column of the confusion matrix.\n",
    "\n",
    "To compute the confusion matrix we first need to have a set of predictions so they can be compared to the actual targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the confusion matrix passing the target classes (y_train_5) and the predicted classes (y_train_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52401,  2178],\n",
       "       [  987,  4434]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in a confusion matrix represents an actual class, while each column represents a predicted class.\n",
    "\n",
    "| Actual Class            | Predicted Negative  | Predicted Positive  |\n",
    "|-------------------------|---------------------|---------------------|\n",
    "| Negative Class (non-5s) | True Negative (TN)  | False Positive (FP) |\n",
    "| Positive Class (5s)     | False Negative (FN) | True Positive (TP)  |\n",
    "\n",
    "* TN - non-5 images correctly classified as non-5s\n",
    "* FP - non-5 images classified as 5s\n",
    "* FN - 5 images wrongly classified as non-5s\n",
    "* TP - 5 images correctly classified as 5\n",
    "\n",
    "The confusion matrix gives us a lot of information but sometimes we may use a more concise metric. An interesting one to look at is the accuracy of the positive predictions; this is called the *precision* of the classifier.\n",
    "\n",
    "$ precision = \\frac{TP}{TP + FP} $\n",
    "\n",
    "A trivial way to have perfect precision is to make one single positive prediction and ensure it is correct (precision 1/1 = 100%). So precision is typically used along with another metric named *recall*, also called *sensitivity* or *true positive rate* (TPR): this is <u>the ratio of positive instances that are correctly detected by the classifier</u>.\n",
    "\n",
    "$ recall = \\frac{TP}{TP + FN} $\n",
    "\n",
    "Let's use Scikit-Learn functions to compute precision and recall metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6705989110707804"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8179302711676812"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the classifier does not look as shiny as it did when we look at the accuracy. When it claims an image represents a 5, it is correct 67% of the time. Moreover, it only detects 82% of the 5s.\n",
    "\n",
    "It is often convenient to combine precision and recall into a single metric called *the F<sub>1</sub> score*. The F<sub>1</sub> score is the harmonic mean of the precision and recall.\n",
    "\n",
    "$ F_{1} = \\frac{TP}{TP + \\frac{FN + FP}{2}} $\n",
    "\n",
    "Let's compute the F<sub>1</sub> score using Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7369733233607579"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F<sub>1</sub> score favors classifiers that have similar precision and recall. In some contexts we mostly care about precision, and others recall.\n",
    "\n",
    "For example, if we train a classifier to detect videos that are safe for kids we will probably prefer a classifier that reject good videos (low recall) but keeps only safe ones (high precision). On the ther hand, suppose we train a classifier to detect shoplifters on survaillance images: it is probably fine if our classifier has only 30% precision as long as it has 99% recall (the security guards will get a few false alerts, but almost all shoplifters will get caught).\n",
    "\n",
    "Unfortunately, we can't have it both ways: increasing precision reduces recall, and vice versa. This is called the *precision/recall tradeoff*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
